{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert path to HAM10000 folder\n",
    "ham10000Path = ''\n",
    "processed = os.path.join(ham10000Path, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 69420\n",
    "trainingDS = image_dataset_from_directory(\n",
    "    processed,\n",
    "    image_size = (600, 450), \n",
    "    validation_split = 0.1,\n",
    "    subset = 'training',\n",
    "    seed = seed,\n",
    "    label_mode = 'categorical'\n",
    ")\n",
    "\n",
    "testingDS = image_dataset_from_directory(\n",
    "    processed, \n",
    "    image_size = (600, 450), \n",
    "    validation_split = 0.1,\n",
    "    subset = 'validation',\n",
    "    seed = seed,\n",
    "    label_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,3,padding=\"same\", activation=\"relu\", input_shape=(600, 450, 3)))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model.add(Conv2D(16,3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model.add(Conv2D(16,3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model.add(Conv2D(16,3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation = \"softmax\"))\n",
    "\n",
    "loss = 'categorical_crossentropy'\n",
    "model.compile(loss = loss, optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseCounts = np.array([327, 514, 1099, 115, 1113, 6705, 142])\n",
    "\n",
    "inverses = 1./baseCounts\n",
    "\n",
    "newWeights = inverses * 10015\n",
    "\n",
    "indices = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "weights = dict(zip(indices, newWeights))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'my_best_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath, \n",
    "    monitor='val_loss',\n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "data = model.fit(\n",
    "    trainingDS,\n",
    "    epochs = epoch,\n",
    "    validation_data = testingDS,\n",
    "    class_weight = weights,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAccuracy = data.history['accuracy']\n",
    "trainLoss = data.history['loss']\n",
    "testAccuracy = data.history['val_accuracy']\n",
    "testLoss = data.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochRange = range(epoch)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochRange, trainAccuracy, label='Training Accuracy')\n",
    "plt.plot(epochRange, testAccuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochRange, trainLoss, label='Training Loss')\n",
    "plt.plot(epochRange, testLoss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  7   8  12   0   3   2   0]\n",
      " [  5  17   7   0   6   5   1]\n",
      " [  7  20  62   3  15  22   1]\n",
      " [  1   3   4   2   0   0   0]\n",
      " [  2   6  25   0  32  49   0]\n",
      " [  5  18  66   1  43 525   0]\n",
      " [  0   3   0   0   2   2   9]], shape=(7, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for x,y in testingDS:\n",
    "  y= tf.argmax(y,axis=1)\n",
    "  y_true.append(y)\n",
    "  y_pred.append(tf.argmax(model.predict(x),axis = 1))\n",
    "  \n",
    "y_pred = tf.concat(y_pred, axis=0)\n",
    "y_true = tf.concat(y_true, axis=0)\n",
    "\n",
    "matrix =  tf.math.confusion_matrix(labels = y_true, predictions = y_pred)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4270d926c00e7b5ef920fa3f6c0a7bf2af0b6b4ffd59adf683658c3cf75fca76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
